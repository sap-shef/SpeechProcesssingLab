{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4f14ba",
   "metadata": {},
   "source": [
    "# Lab Sheet 8 (COM3502-4502-6502 Speech Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c303656",
   "metadata": {},
   "source": [
    "This lab sheet is part of the lecture COM[3502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level3/com3502.html \"Open web page for COM3502 module\")-[4502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level4/com4502.html \"Open web page for COM4502 module\")-[6502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/msc/com6502.html \"Open web page for COM4502 module\") Speech Processing at the [University of Sheffield](https://www.sheffield.ac.uk/ \"Open web page of The University of Sheffield\"), Dept. of [Computer Science](https://www.sheffield.ac.uk/dcs \"Open web page of Department of Computer Science, University of Sheffield\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04248901",
   "metadata": {},
   "source": [
    "It is probably easiest to open this Jupyter Notebook with [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true \"Open in Google Colab\") since GitHub's Viewer does not always show all details correctly. <a href=\"https://colab.research.google.com/github/sap-shef/SpeechProcesssingLab/blob/main/Lab-Sheets/Lab-Sheet-8.ipynb\"><img align=\"right\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open Notebook in Google Colab\" title=\"Open and Execute the Notebook directly in Google Colaboratory\"></a>\n",
    "\n",
    "Please put questions, comments and correction suggestions in the [Blackboard](https://vle.shef.ac.uk) discussion board or send an email to [s.goetze@sheffield.ac.uk](mailto:s.goetze@sheffield.ac.uk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9bb29",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" id='ILOs'>\n",
    "<strong>Intended Learning Objectives (ILOs):</strong><br>\n",
    "    \n",
    "After completing this Jupyter Notebook you should\n",
    "    \n",
    "<ul>\n",
    "<li>Understand the concept of <a href=\"https://en.wikipedia.org/wiki/Overlap%E2%80%93add_method\"><code>Overlap-add algorithm</code></a>\n",
    "</li> \n",
    "<li>Be able to implement your own Overlap-add function\n",
    "</li>    \n",
    "<li>Understand the concept of <a href=\"https://wiki.aalto.fi/display/ITSP/Windowing\"><code>Perfect Reconstruction</code></a> and the Princen-Bradley criteria\n",
    "</li>\n",
    "<li>Denoise a modelled microphone signal via Overlap-add Wiener filtering\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33f3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the ususal necessary and nice-to-have imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import seaborn as sns; sns.set() # styling ((un-)comment if you want)\n",
    "import numpy as np               # math\n",
    "\n",
    "# imports we need in addition for this lab sheet\n",
    "from IPython import display as ipd\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "from scipy.io.wavfile import read as wavread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c0f2e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a id='task_1'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task 1:**\n",
    "    \n",
    "<ul>\n",
    "<li> \n",
    "    Load a WAVE file containing speech, e.g. <code>speech_8kHz_murder.wav</code> from the Internet address <code>https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/</code> and load it into a variable <code>s</code>.\n",
    "</li>\n",
    "    <li> \n",
    "    Generate a signal of white noise of the same length as your speech signal and load it into a variable <code>n</code>. Refer to lab sheet 6 for help.\n",
    "</li>\n",
    "  <li>   \n",
    "    Create a microphone signal $y[k] = s[k]+n[k]$ as shown in the schematic below. Note that the vectors should be cut the same length if needed and the magnitude of the noise signal shouldn't completely drown out the speech signal. Also note that we will do the filtering in the following. \n",
    "\n",
    "<img src=\"NRSingleChannelBasic-web.png\" align=\"center\"/>\n",
    "    </li> \n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da2a9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  328k  100  328k    0     0  1721k      0 --:--:-- --:--:-- --:--:-- 1721k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 57808  100 57808    0     0   482k      0 --:--:-- --:--:-- --:--:--  482k\n"
     ]
    }
   ],
   "source": [
    "# your code here:\n",
    "# load speech wave into variable, s\n",
    "#...\n",
    "\n",
    "# generate white noise signal in variable, n\n",
    "#...\n",
    "\n",
    "# combine both signals to create your microphone signal, y\n",
    "#...\n",
    "\n",
    "# listen to your signal (if you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755bb83",
   "metadata": {},
   "source": [
    "# Overlap-add Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a874385",
   "metadata": {},
   "source": [
    "When processing long duration signals it is common practise to do so by splitting the long signal into a series of shorter segments or chunks. This is primarily for three reasons. First, dealing with the full signal 'in one go' might be impractical due to constraints in computational memory. Second, to attain useful inference from operations such as the discrete Fourier Transform, it is assumed that the signal under scrutiny is time invariant (i.e its statistical properties do not vary with time), this is only typically true when analysing signals over short time frames. Third, for streaming applications where you may be interested in the result whilst still obtaining input data, such as adaptive noise reduction for a phone call.\n",
    "\n",
    "A simple algorithm to perform such chunk-wise processing is the Overlap-Add method.\n",
    "\n",
    "Overlap-Add processing can effectively be broken down into 3 stages:\n",
    "<ul>\n",
    "<li> \n",
    "    <strong>Fragmentation</strong> - Extract windows of size $L$ by iteratively applying a windowing function, such as a Hanning window, to each chunk with each chunk overlapping by a number of $M$ samples. $M$ is often chosen to be $L/2$ in speech processing, i.e the overlapping fraction is that of the window length halved.\n",
    "</li> \n",
    "<li>\n",
    "    <strong>Processing</strong> - Each windowed chunk is processed independently, by convolving with a FIR filter for example.\n",
    "</li>\n",
    "<li>\n",
    "    <strong>Reconstruction</strong> - The processed chunks are 'added' back together sequentially to retain each chunk's relative position in the original signal.\n",
    "</li>\n",
    "</ul>\n",
    "    \n",
    "\n",
    "The process is described mathematically below where a long signal, $x[k]$, is to be convolved with a finite impulse response filter, $h[k]$.  \n",
    "\n",
    "1.&emsp;Applying a window function centered at the $i$th sample with window $w$ of length $L$, whose value is 0 beyond $-L/2$ and $+L/2$:\n",
    "\n",
    "$$x_i[k] = x[k]w^L_i[k]$$\n",
    "\n",
    "2.&emsp;Fragmentation of signal:\n",
    "\n",
    "$$x[k] = x_0[k] + x_1[k] + x_2[k] + ... $$\n",
    "\n",
    "3.&emsp;Application of filter to fragmented signal: \n",
    "\n",
    "$$y[k]=\\sum_{i=0}^{N-1}x_{k-i}\\cdot h[i]$$  \n",
    "\n",
    "4.&emsp;Use the distributive property of convolution to formulate as blockwise:\n",
    "\\begin{align*}\n",
    "y[k]=&\\sum_{i=0}^{N-1}x[k-i]h[i]\n",
    "\\\\=&\\sum_{i=0}^{N-1}(x_{0}[k-i]+x_{1}[k-i]+...)\\cdot h[i]\n",
    "\\\\=&\\sum_{i=0}^{N-1}x_{0}[k-i]\\cdot h[i]+\\sum_{i=0}^{N-1}x_{1}[k-i]\\cdot h[i] + ...\n",
    "\\\\=&\\:\\mathrm{IFFT}\\left \\{ x_{0}[n]h[n]\\right \\} + \\mathrm{IFFT}\\left \\{ x_{1}[n]h[n]\\right \\} +...\n",
    "\\\\=&\\: y_{0}[k] + y_{1}[k] + ...\n",
    "\\end{align*}\n",
    "\n",
    "Since speech signals are time variant in nature, it is beneficial to utilise the Overlap-Add algorithm during the processing of them. This is based on the assumption that, heuristically speaking, fragmented speech present in each chunk may roughly represents a phoneme.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<a id='task_1'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task 2: Perform windowing on your modelled microphone signal.**\n",
    "    \n",
    "<ul>\n",
    "<li> Extract a short temporal range from your modelled microphone signal; around 1 second of audio.\n",
    "</li>     \n",
    "<li>\n",
    "    Finish the below function to iterate through said range applying a windowing function from the numpy library to each iteration. \n",
    "</li>\n",
    "<li>\n",
    "       Have the function return a list or np.array() all extracted chunks, with each chunk padded with zeros so that all chunks are of the same length as the original input.\n",
    "</li>\n",
    "<li>\n",
    "       Test your function with the Blackman filter.\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e6e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(sample, chunk_length = 0.03, fs = 8000, window_choice = 'Blackman'):\n",
    "    \"\"\"\n",
    "    Extracts windowed segments from a signal for a given phoneme duration using a windowing\n",
    "    function from the numpy library.\n",
    "    \n",
    "    Input:\n",
    "        sample: list or np.array\n",
    "            input signal to window\n",
    "        chunk_length: float\n",
    "            desired chunk length in seconds\n",
    "        fs: int\n",
    "            sampling frequency of signal\n",
    "        window_choice: str\n",
    "            windowing function to use, one of: Blackman, Hamming, Hanning\n",
    "    Output:\n",
    "        list of np.arrays\n",
    "    \n",
    "    Example:\n",
    "       chunks = get_windows(sample, chunk_length = 0.025, fs=8000, window_choice = 'hanning')\n",
    "    \"\"\"\n",
    "    ## suggested method: \n",
    "    # find chunk centres first\n",
    "    # iterate through your window centres with a for loop\n",
    "    # use a dictionary to accept the window choice argument as an input and output the appropriate function from np\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada06c8",
   "metadata": {},
   "source": [
    "## Princen-Bradley Criteria\n",
    "\n",
    "A desired property of the windowing process used in an Overlap-Add algorithm is that the windowing itself should not significantly alter the original signal after signal reconstruction. This is known as the Princen-Bradley Criteria.\n",
    "\n",
    "\n",
    "<br>\n",
    "<a id='task_1'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Task 3: Try your windowing function with the phoneme_duartion as 0.03 seconds and window_choice = 'Blackman'. Do you think the output from this configuration satisfies the Princeton-Bradley Criteria?**\n",
    "    \n",
    "**Hint**: You can test this by simply summing the output of your window function and subtracting this from your original shortened microphone signal.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8428e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# reconstruct your windowed signal\n",
    "#...\n",
    "\n",
    "# plot\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a2c3e",
   "metadata": {},
   "source": [
    "## Weiner Filtering\n",
    "A simple method to reduce the effects of the white noise we added to our modelled microphone signal in task 1 is to apply a Wiener filter. The Wiener filter is defined below where $h[n]$ is the impulse response of the filter $\\Phi_{yy}$, is the Power Spectral Density of the filter and $\\Phi_{n}$ is the Power Spectral Density of the filter.\n",
    "\n",
    "$$h[n]=\\frac{\\Phi_{yy}-\\Phi_{n}}{\\Phi_{yy}}$$\n",
    "\n",
    "<br>\n",
    "<a id='task_1'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Task 4: Apply the Wiener filter to 2 chunks of your modelled microphone signal**\n",
    "    \n",
    "<ul>\n",
    "<li> Use scipy.sig.wiener() to apply Wiener filtering to each of the 2 chunks from your modelled microphone signal.\n",
    "</li>  \n",
    "<li> Plot the power spectral density function before and after applying the filter for each chunk.\n",
    "</li>     \n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93bca738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#your code here..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9da695",
   "metadata": {},
   "source": [
    "## Overlap-Add Function\n",
    "Now that we have observed the effects of the Wiener filter and how windowing can be performed, you should now have the tools to create your own Overlapp-add Weiner filtering function. \n",
    "\n",
    "<br>\n",
    "<a id='task_1'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "    \n",
    "**Task 5: Finish the function below to implement the Overlap-Add algorithm to perform Weiner filtering.**\n",
    "    \n",
    "<ul>\n",
    "<li> Create a list of evenly spaced chunks from your signal, with a 50% overlapping fraction.\n",
    "</li>     \n",
    "<li> Apply a Hanning window to each chunk.\n",
    "</li>     \n",
    "<li> \n",
    "   Perform Wiener filtering using the scipy library on each chunk.\n",
    "</li> \n",
    "<li> \n",
    "   Reconstruct each filtered chunk to obtain the full filtered signal.\n",
    "</li>\n",
    "<li>\n",
    "     Aurally compare with the non-filtered signal, have you successfully denoised the signal?\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7ba18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_add_filtering(signal, chunk_length):\n",
    "    \"\"\"\n",
    "    Overlap-Add filtering.\n",
    "    \n",
    "    Input:\n",
    "        signal: np.array or list\n",
    "            input signal to process\n",
    "        chunk_length: int\n",
    "            size of \n",
    "    Output:\n",
    "        filtered signal\n",
    "    \n",
    "    Example:\n",
    "       overlap_add_filtering(signal, testfilt, 1000)\n",
    "    \"\"\"\n",
    "    bits_to_shift_by = (L_I-1).bit_length() # number of bits necessary to represent in binary\n",
    "    L_F = 2<<bits_to_shift_by # length of fourier transform window\n",
    "    L_W = L_F - L_I + 1 # length of signal to be filtered in single window overlap iteration\n",
    "    \n",
    "    filt_F = np.fft.rfft(filt, n=L_F) # filter in frequency domain\n",
    "    \n",
    "    \n",
    "    #YOUR WORK HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    return signal_f[:len(signal)] #truncate to length of original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call to test your function\n",
    "# ...\n",
    "\n",
    "# aurally compare with noisy signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85166cfb",
   "metadata": {},
   "source": [
    "## Copyright\n",
    "\n",
    "This notebook is licensed to be used during the lecture COM[3502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level3/com3502.html \"Open web page for COM3502 module\")-[4502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level4/com4502.html \"Open web page for COM4502 module\")-[6502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/msc/com6502.html \"Open web page for COM4502 module\") Speech Processing at the [University of Sheffield](https://www.sheffield.ac.uk/ \"Open web page of The University of Sheffield\"), Dept. of [Computer Science](https://www.sheffield.ac.uk/dcs \"Open web page of Department of Computer Science, University of Sheffield\"). Any further use (beyond use for the lecture) is only permitted if agreed with the [module lead](mailto:s.goetze@sheffield.ac.uk). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
